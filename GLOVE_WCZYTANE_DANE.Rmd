Definicja funkcji 

```{r}
proc_pretrained_vec <- function(p_vec) {
  # initialize space for values and the names of each word in vocab
  vals <- vector(mode = "list", length(p_vec))
  names <- character(length(p_vec))

  # loop through to gather values and names of each word
  for(i in 1:length(p_vec)) {
    if(i %% 1000 == 0) {print(i)}
    this_vec <- p_vec[i]
    this_vec_unlisted <- unlist(strsplit(this_vec, " "))
    this_vec_values <- as.numeric(this_vec_unlisted[-1])  # this needs testing, does it become numeric?
    this_vec_name <- this_vec_unlisted[1]

    vals[[i]] <- this_vec_values
    names[[i]] <- this_vec_name
  }

  # convert lists to data.frame and attach the names
  glove <- data.frame(vals)
  names(glove) <- names

  return(glove)
}
```

Wczytanie 

```{r}
setwd("D:/PW-MAGISTERSKIE/PW-Magisterskie-sem2/ZUM/Projekt/ZUM_Proj")
    
g6b <- scan(file = "Data/glove.6B/glove.6B.50d.txt", what="", sep="\n")

glove <- proc_pretrained_vec(g6b)
    
print(dim(glove)) 
```
Wektory podobne

```{r}
glove_T = t(glove)
library(text2vec)
```



```{r}
fruit = glove_T["king", , drop = FALSE] - glove_T["man", , drop = FALSE] + glove_T["woman", , drop = FALSE]  
cos_sim = sim2(x = glove_T, y = fruit, method = "cosine", norm = "l2") 
# odległość cosinusowa https://cran.r-project.org/web/packages/text2vec/text2vec.pdf str 29
head(sort(cos_sim[,1], decreasing = TRUE), 5)
```

```{r}
fruit = glove_T["flock", , drop = FALSE] - glove_T["geese", , drop = FALSE] + glove_T["buffalo", , drop = FALSE]  
cos_sim = sim2(x = glove_T, y = fruit, method = "cosine", norm = "l2") 
# odległość cosinusowa https://cran.r-project.org/web/packages/text2vec/text2vec.pdf str 29
head(sort(cos_sim[,1], decreasing = TRUE), 5)
```

```{r}
fruit = glove_T["flock", , drop = FALSE] - glove_T["geese", , drop = FALSE] + glove_T["bison", , drop = FALSE]  
cos_sim = sim2(x = glove_T, y = fruit, method = "cosine", norm = "l2") 
# odległość cosinusowa https://cran.r-project.org/web/packages/text2vec/text2vec.pdf str 29
head(sort(cos_sim[,1], decreasing = TRUE), 5)
```


Przygotowanie danych
```{r}
df <- read.csv(
  file = 'Data/winemag-data-130k-v2.csv',
  sep = ','
)

df2 <- df[,colSums(is.na(df["description"]))<nrow(df)]
df2[["description"]] <- tolower(df2[["description"]])

library(stringr)
df2[["description"]] <-str_replace(gsub("([^a-z'])", " ", df2[["description"]]), "B", "b") 
df2[["description"]] <-str_replace(gsub("\\s+", " ", df2[["description"]]), "B", "b") 
df2[["description"]] <-str_replace(gsub("\\s$", "", df2[["description"]]), "B", "b")


#Sprawdzanie
df2[29996,"description"]
df[29996,"description"]
df2[502,"description"]
df[502,"description"]
```
Klasy ze wsględu na points
```{r}
dyskretyzacja <- function(x) {
  if(x<82) {
    1
  }
  else if(x<84) {
    2
  }
  else if(x<86) {
    3
  }
  else if(x<88) {
    4
  }
  else{
    5
  }
}

df2$points<-apply(array(df2[["points"]]),MARGIN=1, FUN=dyskretyzacja)
```

Podział danych (Przy uczeniu na naszych danych)
Jaką częśc danych bierzemy czy na tym etapie wszyskie vektory musimy zrobić

```{r}
#
library(data.table)
#library(magrittr)
#data("df2")
setDT(df2)
setkey(df2, X)
set.seed(2017L)
all_ids = df2$X
train_ids = setdiff(all_ids, -1)
#test_ids = setdiff(all_ids, train_ids)
train = df2[J(train_ids)]
#test = df2[J(test_ids)]

```

Robienie Tokenów
```{r}
tokens = word_tokenizer(df2$description)
```

Jak działa oczyszczanie ?
```{r}
words <- row.names(glove_T)
writeLines("intersect\n")
intersect(tokens[[1]],words)
writeLines("\noriginal\n")
tokens[[1]]
```

Czyszczenie tokenóW

Trwa długo sprawdzanie części wspólnej z ogromnym words za każdym razem 

!!!może wcześniej zrobić intersekcje words ze słowami występującymi by ograniczyć czas przeszukiwania ?!!!
```{r}
t1 = Sys.time()
tokens_clear <- lapply(tokens, function(x) intersect(x,words))
print(difftime(Sys.time(), t1, units = 'sec'))

```


Docs Vecs
```{r}
t1 = Sys.time()
doc_vectors_list <- lapply(tokens_clear, function(x) colMeans(glove_T[x,]))
print(difftime(Sys.time(), t1, units = 'sec'))
```

